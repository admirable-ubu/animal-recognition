{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from functions import (convert_to_binary, select_half_video, extractMobilNetfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# PARAMETER SETTING\n",
    "cnn_flag = True # train own CNN \n",
    "\n",
    "transfer_MobileNetV2_flag_1 = True \n",
    "# fine-tune pretrained MobileNetV2 \n",
    "\n",
    "r = 56 # target image size        \n",
    "ne = 200 ###########200 # number of epochs for CNN training\n",
    "eta = 0.0001 # training rate\n",
    "\n",
    "\n",
    "Videos = ['Pigs_49651_960_540_500f', 'Koi_5652_952_540',\\\n",
    "          'Pigeons_8234_1280_720','Pigeons_4927_960_540_600f', \\\n",
    "          'Pigeons_29033_960_540_300f']\n",
    "\n",
    "cl_names = ['Linear Discriminant Analysis', '3-nn', 'Decision Tree',\n",
    "            'SVM', 'Bagging', 'Random Forest']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "# CALCULATIONS\n",
    "\n",
    "data_path = \"../data/\"\n",
    "training_fold = 1 # 1 or 2\n",
    "test_fold = 3 - training_fold\n",
    "\n",
    "for video in Videos:\n",
    "    \n",
    "    print('\\n\\n#####  ' + video + '  #####\\n\\n')\n",
    "    \n",
    "    folder = os.path.join(data_path, video + \"_clips\")\n",
    "    bb_file = os.path.join(data_path, \"BB_\" + video + \".csv\")\n",
    "\n",
    "    # Read training and testing data (half video; must not be random!)\n",
    "    imds_1,labels_1 = select_half_video(folder,bb_file,part = training_fold) # training\n",
    "    imds_2,labels_2 = select_half_video(folder,bb_file,part = test_fold) # testing\n",
    "    \n",
    "    ll1 = list(np.sort(np.unique(labels_1)))\n",
    "    ll2 = list(np.sort(np.unique(labels_2)))\n",
    "    \n",
    "    ll = list(np.sort(np.unique(ll1+ll2)))\n",
    "    n_classes = len(ll1)    \n",
    "\n",
    "    X_train_im = []\n",
    "    X_train = []\n",
    "    y_train_num = []\n",
    "    for i in range(len(imds_1)):\n",
    "        y_train_num.append(ll.index(labels_1[i]))\n",
    "        X_train.append(resize(imds_1[i], (r, r)))\n",
    "        X_train_im.append(imds_1[i])\n",
    "    y_train,_ = convert_to_binary(y_train_num,n_classes)\n",
    "    X_train = np.array(X_train)/255                       \n",
    "\n",
    "    X_test_im = []\n",
    "    X_test = []\n",
    "    y_test_num = [] # numerical testing labels\n",
    "    for i in range(len(imds_2)):\n",
    "        if labels_2[i] in set(ll):\n",
    "            y_test_num.append(ll.index(labels_2[i]))\n",
    "            X_test.append(resize(imds_2[i], (r, r)))\n",
    "            X_test_im.append(imds_2[i])\n",
    "\n",
    "    y_test,_ = convert_to_binary(y_test_num,len(ll))  \n",
    "    X_test = np.array(X_test)/255    \n",
    "\n",
    "    print('Training size = ',X_train.shape,' Testing size = ',X_test.shape)\n",
    "    \n",
    "    # Augment training data (just in case)\n",
    "    datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.2, # Randomly zoom image \n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip = True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    out_fn = video        \n",
    "\n",
    "    if cnn_flag:\n",
    "        # CNN\n",
    "        #==============================\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(r,r,3)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(n_classes, activation='softmax'))\n",
    "        #==============================\n",
    "\n",
    "        opt = Adam(learning_rate = eta)\n",
    "        model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "        history = model.fit(datagen.flow(X_train,y_train),epochs = ne, verbose = True)\n",
    "\n",
    "        acc = history.history['accuracy']\n",
    "        loss = history.history['loss']\n",
    "        epochs_range = range(ne)\n",
    "        plt.figure() # figsize=(15, 15))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(epochs_range, acc)\n",
    "        plt.title('Training Accuracy')\n",
    "        plt.subplot(122)\n",
    "        plt.plot(epochs_range, loss)\n",
    "        plt.title('Training Loss')\n",
    "\n",
    "        predictions = model.predict(X_test) # assigned probabilities\n",
    "        y_assigned = np.argmax(predictions, axis=-1) # assigned labels\n",
    "\n",
    "        testing_accuracy = np.mean(y_test_num == y_assigned)\n",
    "        print('Testing accuracy = ', testing_accuracy)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test_num,y_assigned)\n",
    "        plt.figure() \n",
    "        sns.heatmap(cm, xticklabels = ll, yticklabels = ll)        \n",
    "        \n",
    "        # Save results\n",
    "\n",
    "        TrainingAccLoss = np.hstack((np.reshape(acc,(-1,1)),np.reshape(loss,(-1,1))))\n",
    "        np.savetxt(\"TrainingAccLoss_\"+out_fn+\"_fold\"+str(training_fold)+\".csv\", TrainingAccLoss, delimiter=\",\")\n",
    "        \n",
    "        TestingLabelsAssignedLabels = np.hstack( \\\n",
    "            (np.reshape(y_test_num,(-1,1)),np.reshape(y_assigned,(-1,1))))\n",
    "        np.savetxt(\"TestingLabelsAssignedLabels_\"+ \\\n",
    "            out_fn+\"_fold\"+str(training_fold)+\".csv\", TestingLabelsAssignedLabels, delimiter=\",\")\n",
    "\n",
    "    if transfer_MobileNetV2_flag_1:\n",
    "        #================================================================\n",
    "        # TRANSFER LEARNING (1) MobileNetV2 - further NN model\n",
    "\n",
    "        base_model = tf.keras.applications.MobileNetV2(input_shape = \\\n",
    "           (r, r, 3), include_top = False, weights = \"imagenet\")\n",
    "\n",
    "        base_model.trainable = False\n",
    "        model = tf.keras.Sequential([base_model,\n",
    "             tf.keras.layers.GlobalAveragePooling2D(),\n",
    "             tf.keras.layers.Dropout(0.2),\n",
    "             tf.keras.layers.Dense(n_classes, activation=\"softmax\")                                     \n",
    "            ])\n",
    "        base_learning_rate = eta\n",
    "        model.compile(optimizer = \\\n",
    "                      tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(datagen.flow(X_train, \\\n",
    "                     y_train),epochs = ne, verbose = True)\n",
    "\n",
    "        predictions = model.predict(X_test) # assigned probabilities\n",
    "        y_assigned = np.argmax(predictions, axis=-1) # assigned labels\n",
    "\n",
    "        testing_accuracy = np.mean(y_test_num == y_assigned)\n",
    "        print('Testing accuracy MobileNetV2= ', testing_accuracy)\n",
    "        \n",
    "        TestingLabelsAssignedLabels = np.hstack( \\\n",
    "            (np.reshape(y_test_num,(-1,1)),np.reshape(y_assigned,(-1,1))))\n",
    "        np.savetxt(\"TestingLabelsAssignedLabelsMobileNetV2_\"+ \\\n",
    "            out_fn+\"_fold\"+str(training_fold)+\".csv\", TestingLabelsAssignedLabels, delimiter=\",\")     \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
